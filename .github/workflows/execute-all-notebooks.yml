name: Execute All Notebooks

on:
  workflow_dispatch:
    inputs:
      # FUTURE USE:
      # Maintainers can provide a PR number or existing upstream branch name to run this
      # job against. If no PR number or branch name is provided, this job will run against
      # content in the "main" branch instead.
      pr_or_branch:
        description: "Pull request number or branch name"
        required: true
        default: "main"
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - "notebooks/**/*.ipynb"
      - ".github/workflows/execute-all-notebooks.yml"
env:
  INSTANCE_TYPE: "g6e.xlarge"

# We don't need anything other than Bash for our shell..
defaults:
  run:
    shell: bash

jobs:
  launch-ec2-runner:
    runs-on: ubuntu-latest
    permissions:
      id-token: write # This is required for OIDC (AWS auth)
      contents: read
    outputs:
      label: ${{ steps.start-ec2-runner.outputs.label }}
      ec2-instance-id: ${{ steps.start-ec2-runner.outputs.ec2-instance-id }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@00943011d9042930efac3dcd3a170e4273319bc8 # v5.1.0
        with:
          role-to-assume: "arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/${{ vars.DATA_PROCESSING_IAM_ROLE }}"
          aws-region: us-east-2
          role-session-name: odh-data-processing  # For tracking in CloudTrail

      - name: Start Data Processing EC2 runner
        id: start-ec2-runner
        uses: machulav/ec2-github-runner@a6dbcefcf8a31a861f5e078bb153ed332130c512 # v2.4.3
        with:
          mode: start
          github-token: "${{ secrets.DATA_PROCESSING_GH_PERSONAL_ACCESS_TOKEN }}"
          ec2-instance-type: "${{ env.INSTANCE_TYPE }}"
          availability-zones-config: >
            [
              {"imageId": "${{ vars.US_EAST_2_AMI_ID }}", "subnetId": "${{ vars.US_EAST_2A_SUBNET_ID }}", "securityGroupId": "${{ vars.US_EAST_2_SG_ID }}"},
              {"imageId": "${{ vars.US_EAST_2_AMI_ID }}", "subnetId": "${{ vars.US_EAST_2B_SUBNET_ID }}", "securityGroupId": "${{ vars.US_EAST_2_SG_ID }}"},
              {"imageId": "${{ vars.US_EAST_2_AMI_ID }}", "subnetId": "${{ vars.US_EAST_2C_SUBNET_ID }}", "securityGroupId": "${{ vars.US_EAST_2_SG_ID }}"}
            ]
          iam-role-name: "${{ vars.DATA_PROCESSING_IAM_ROLE }}"
          aws-resource-tags: >
            [
              {"Key": "Name", "Value": "data-processing-gh-runner"},
              {"Key": "GitHubRepository", "Value": "${{ github.repository }}"},
              {"Key": "GitHubRef", "Value": "${{ github.ref }}"},
              {"Key": "GitHubPR", "Value": "${{ github.event.number }}"}
            ]
  execute-all-notebooks:
    needs:
      - launch-ec2-runner
    runs-on: ${{ needs.launch-ec2-runner.outputs.label }}

    steps:
      - name: Setup Environment
        run: echo "Running on EC2 ${{ needs.launch-ec2-runner.outputs.ec2-instance-id }}"

      - uses: actions/checkout@v4

      - name: Setup System Dependencies (Python + CUDA Runtime)
        run: |
          # 1. Install Python and basic tools
          sudo dnf install -y gcc gcc-c++ make git-core python3.11 python3.11-devel python3-pip libaio
          
          # 2. Install base runtime libraries (required by libcusparselt)
          sudo dnf install -y cuda-libraries-12-4
          
          # 3. Install the specific library Docling needs
          sudo dnf install -y libcusparselt0-cuda-12.x86_64
          sudo dnf install -y nvshmem || echo "NVSHMEM not in repo, relying on pip"
          
          # 4. THE SAFETY CHECK: Hide System NCCL
          # We remove the system libnccl so that when we put system paths first in LD_LIBRARY_PATH,
          # PyTorch won't accidentally find this incompatible version.
          sudo find /usr/lib64 /usr/local/cuda-*/lib64 -name "libnccl.so*" -exec rm -f {} \;

      - name: Install Python Dependencies
        run: |
          # Setup Pip
          /usr/bin/python3.11 -m ensurepip --upgrade >/dev/null 2>&1 || true
          /usr/bin/python3.11 -m pip install --upgrade pip setuptools wheel
          
          # 1. Install Requirements (Generic)
          # We do this first so we can overwrite any bad CPU-versions it pulls in
          /usr/bin/python3.11 -m pip install -r requirements-dev.txt
          /usr/bin/python3.11 -m pip install -r scripts/subset_selection/requirements.txt
          
          # 2. Force Reinstall GPU-Specific Versions (From PyTorch Index)
          # We run this separately so --index-url doesn't break other packages
          /usr/bin/python3.11 -m pip install --force-reinstall \
            torch torchvision torchaudio \
            --index-url https://download.pytorch.org/whl/cu121
            
          # 3. Force Reinstall Standard Tools (From Default PyPI Index)
          /usr/bin/python3.11 -m pip install \
             papermill ipykernel jupyter "docling[chunking]" datasets pymilvus h5py
          
          # 4. Register Kernel
          /usr/bin/python3.11 -m ipykernel install --name "python3.11" --user

      - name: Execute Notebooks
        run: |
          export PYTHONPATH="$(pwd):$PYTHONPATH"
          
          # 1. Find the pip installation folder
          SITE_PACKAGES=$(/usr/bin/python3.11 -m pip show nvidia-nccl-cu12 | grep Location | awk '{print $2}')
          
          # 2. Define ALL bundled library paths
          # NVIDIA-specific libs (Network/Math)
          NCCL_LIB="$SITE_PACKAGES/nvidia/nccl/lib"
          NVSHMEM_LIB="$SITE_PACKAGES/nvidia/nvshmem/lib"
          CUSPARSE_LIB="$SITE_PACKAGES/nvidia/cusparse/lib"
          # Core PyTorch libs (libtorch_cuda.so, etc.)
          TORCH_LIB="$SITE_PACKAGES/torch/lib"
          
          # 3. THE COMPLETE SANDWICH PATH
          # Layer 1: System Standard (/usr/lib64). 
          #          - Usage: Milvus (libstdc++, libaio).
          #          - Safety: We deleted the bad libnccl here in previous step, so PyTorch is safe.
          
          # Layer 2: Bundled Pip Libs.
          #          - Usage: PyTorch (libnccl, libnvshmem, libtorch_cuda).
          
          # Layer 3: System CUDA (/usr/local/cuda/lib64).
          #          - Usage: Docling (libcusparselt).
          
          export LD_LIBRARY_PATH="/usr/lib64:$NCCL_LIB:$NVSHMEM_LIB:$CUSPARSE_LIB:/usr/local/cuda/lib64:$LD_LIBRARY_PATH"
          
          # Debug output to confirm
          echo "LD_LIBRARY_PATH is: $LD_LIBRARY_PATH"
          
          # 3. Run Tests
          cd tests
          /usr/bin/python3.11 -m pytest test_notebook_execution.py -v --tb=short
  stop-ec2-runner:
    permissions:
      id-token: write # This is required for OIDC (AWS auth)
      contents: read
    needs:
      - launch-ec2-runner
      - execute-all-notebooks
    runs-on: ubuntu-latest
    if: ${{ always() }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@00943011d9042930efac3dcd3a170e4273319bc8 # v5.1.0
        with:
          role-to-assume: "arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/${{ vars.DATA_PROCESSING_IAM_ROLE }}"
          aws-region: us-east-2
          role-session-name: odh-data-processing  # For tracking in CloudTrail

      - name: Stop EC2 runner
        uses: machulav/ec2-github-runner@fcfb31a5760dad1314a64a0e172b78ec6fc8a17e # v4.3.2
        with:
          mode: stop
          github-token: "${{ secrets.DATA_PROCESSING_GH_PERSONAL_ACCESS_TOKEN }}"
          label: ${{ needs.launch-ec2-runner.outputs.label }}
          ec2-instance-id: ${{ needs.launch-ec2-runner.outputs.ec2-instance-id }}
